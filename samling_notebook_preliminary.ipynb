{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ser5kovskiy/Multi_MRI_diffusion/blob/main/samling_notebook_preliminary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive2')"
      ],
      "metadata": {
        "id": "qJdOAJwUa_IR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0TLWqNvYtKt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from functools import partial\n",
        "import os\n",
        "import argparse\n",
        "import yaml\n",
        "\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_data = '/content/drive2/MyDrive/deep_generative_model_project/'"
      ],
      "metadata": {
        "id": "DOHDp64LYwR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0, path_to_data)"
      ],
      "metadata": {
        "id": "JiQBOe1VYuUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from distutils.dir_util import copy_tree\n",
        "\n",
        "folder_to_copy = ['data', 'guided_diffusion',]\n",
        "\n",
        "for folder in folder_to_copy:\n",
        "    dest_path = os.path.join(path_to_data, folder)\n",
        "    target_path = os.path.join('.', folder)\n",
        "    copy_tree(dest_path, target_path)"
      ],
      "metadata": {
        "id": "VmhycDIla1q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uqC2Kf6FHD_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from guided_diffusion.condition_methods import get_conditioning_method\n",
        "from guided_diffusion.measurements import get_noise, get_operator\n",
        "from guided_diffusion.unet import create_model\n",
        "from guided_diffusion.gaussian_diffusion import create_sampler\n",
        "from data.dataloader import get_dataset, get_dataloader"
      ],
      "metadata": {
        "id": "WuQkAUBRY1YJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage import io\n",
        "import numpy as np\n",
        "from torch.backends import cudnn\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "seed = 42\n",
        "cudnn.benchmark = False\n",
        "cudnn.deterministic = True\n",
        "random.seed(seed)  # Set SEED for the Random module\n",
        "np.random.seed(seed)  # Set SEED for np.random module\n",
        "torch.manual_seed(seed)   # Set the random number seed\n",
        "torch.cuda.manual_seed(seed)  # Set the current GPU random seed\n",
        "torch.cuda.manual_seed_all(seed)  # Set random seed for all GPUs"
      ],
      "metadata": {
        "id": "MEGVOc0rZMMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_yaml(file_path: str) -> dict:\n",
        "    with open(file_path) as f:\n",
        "        config = yaml.load(f, Loader=yaml.FullLoader)\n",
        "    return config"
      ],
      "metadata": {
        "id": "MGbNjBFbda-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 15\n",
        "device_str = f\"cuda\" if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "dataset_name = 'brain_nii'\n",
        "folder_congigs = f'experiments_{dataset_name}'\n",
        "\n",
        "#dataset_name = input()\n",
        "#folder_congigs = input()\n",
        "\n",
        "result_folder_parent_part = os.path.join(path_to_data, f'{dataset_name}/res')\n",
        "\n",
        "config_folder = os.path.join(path_to_data, f'configs/{dataset_name}/experiments/{folder_congigs}')"
      ],
      "metadata": {
        "id": "0omMFtJEdcgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_config = load_yaml(f'{config_folder}/model_config_MRI_T1.yaml')\n",
        "diffusion_config = load_yaml(f'{config_folder}/diffusion_config.yaml')\n",
        "task_config = load_yaml(f'{config_folder}/MRI_config_hyperparameters_one_object_test_05.yaml')\n",
        "dataset_mode = task_config['data']['folder'].split('/')[-1]"
      ],
      "metadata": {
        "id": "tiHOVo6MebMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(device_str)\n",
        "model = create_model(**model_config)\n",
        "model = model.to(device)\n",
        "model = model.eval()"
      ],
      "metadata": {
        "id": "GcGg9LDfpvvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "measure_config = task_config['measurement']\n",
        "operator = get_operator(device=device, **measure_config['operator'])\n",
        "noiser = get_noise(**measure_config['noise'])"
      ],
      "metadata": {
        "id": "VGbQJmb5yS_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modalities = [0, 1]\n",
        "a = int(input())\n",
        "if(a != 0):\n",
        "    modalities = modalities[a - 1]"
      ],
      "metadata": {
        "id": "9Fbluo36FLqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert modalities + 1 == int(model_config['model_path'][-4])"
      ],
      "metadata": {
        "id": "ruaifi2Qn1vF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_config = task_config['data']\n",
        "data_config['modalities'] = modalities"
      ],
      "metadata": {
        "id": "o_KbWkqdGASr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_config"
      ],
      "metadata": {
        "id": "yzgLB7UMMcbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = get_dataset(**data_config)\n",
        "loader = get_dataloader(dataset, batch_size=batch_size, num_workers=0, train=False,)"
      ],
      "metadata": {
        "id": "QbMEOqzjqS2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modalities_num = dataset[0][0].shape[0]\n",
        "modalities_num"
      ],
      "metadata": {
        "id": "5beFAHzL8X1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from skimage.metrics import structural_similarity, mean_squared_error, peak_signal_noise_ratio\n",
        "import imageio as io\n",
        "\n",
        "def saving_object(parent_dir, obj_type, obj_num, obj):\n",
        "    obj = np.hstack((obj[...,0], obj[...,1]))\n",
        "    obj = Image.fromarray(obj)\n",
        "\n",
        "    path_to_save = os.path.join(parent_dir, obj_type, f'{obj_num}.jpeg')\n",
        "    os.makedirs(os.path.dirname(path_to_save), exist_ok=True)\n",
        "    io.imwrite(path_to_save, obj, format='jpeg')\n",
        "\n",
        "def object_metrics(prediction, GT):\n",
        "    obj_SSIM = []\n",
        "    obj_PSNR = []\n",
        "    #GT = (GT * 255).astype(np.uint8)\n",
        "    #prediction = (prediction * 255).astype(np.uint8)\n",
        "    for idx in range(GT.shape[2]):\n",
        "        cur_GT = GT[:,:,idx]\n",
        "        cur_pred = prediction[:,:,idx]\n",
        "        obj_SSIM += [structural_similarity(cur_GT, cur_pred)]\n",
        "        obj_PSNR += [peak_signal_noise_ratio(cur_GT, cur_pred)]\n",
        "    obj_SSIM = np.array(obj_SSIM)\n",
        "    obj_PSNR = np.array(obj_PSNR)\n",
        "    return obj_SSIM, obj_PSNR\n",
        "\n",
        "def metrics_calculate(prediction, GT, raw_data, cur_objs_num, parent_dir, middle_result_txt_file):\n",
        "    prediction = np.moveaxis(np.array(prediction), 1, -1)\n",
        "    GT = np.moveaxis(np.array(GT[:,:,0,]), 1, -1)\n",
        "    raw_data = np.moveaxis(np.array(raw_data[:,:,0,]), 1, -1)\n",
        "\n",
        "    prediction = (prediction * 255).astype(np.uint8)\n",
        "    GT = (GT * 255).astype(np.uint8)\n",
        "    raw_data = (raw_data * 255).astype(np.uint8)\n",
        "\n",
        "    idx = 0\n",
        "    set_batch_SSIM = np.array([0.,] * prediction.shape[1])\n",
        "    set_batch_PSNR = np.array([0.,] * prediction.shape[1])\n",
        "\n",
        "    for idx, cur_obj in enumerate(zip(prediction, GT, raw_data)):\n",
        "        cur_pred, cur_GT, cur_raw = cur_obj\n",
        "\n",
        "        saving_object(parent_dir=parent_dir, obj_type = 'recon',\n",
        "                      obj_num=cur_objs_num + idx, obj = cur_pred)\n",
        "\n",
        "        saving_object(parent_dir=parent_dir, obj_type = 'label',\n",
        "                      obj_num=cur_objs_num + idx, obj = cur_GT)\n",
        "\n",
        "        saving_object(parent_dir=parent_dir, obj_type = 'input',\n",
        "                      obj_num=cur_objs_num + idx, obj = cur_raw)\n",
        "\n",
        "        cur_obj_metrics = object_metrics(prediction=cur_pred, GT=cur_GT)\n",
        "        print(f'object:{cur_objs_num + idx} ', cur_obj_metrics)\n",
        "        result_line = f'object:{cur_objs_num + idx} - SSIM: {cur_obj_metrics[0]} PSNR:{cur_obj_metrics[1]} SSIM mean: {np.mean(cur_obj_metrics[0])} PSNR common: {np.mean(cur_obj_metrics[1])}\\n'\n",
        "        with open(middle_result_txt_file, 'a+') as file:\n",
        "            file.write(result_line)\n",
        "\n",
        "        set_batch_SSIM += cur_obj_metrics[0]\n",
        "        set_batch_PSNR += cur_obj_metrics[1]\n",
        "    return set_batch_SSIM, set_batch_PSNR\n",
        "\n",
        "def fftc(image):\n",
        "    kspace = torch.fft.fftshift(torch.fft.fft2(image), dim=(-2,-1))\n",
        "    return kspace\n",
        "\n",
        "def ifftc(kspace):\n",
        "    image = torch.fft.ifft2(torch.fft.ifftshift(kspace, dim=(-2,-1)))\n",
        "    return image\n",
        "\n",
        "def call_metrics(sample,\n",
        "                 batch,\n",
        "                 measurement,\n",
        "                 mask,\n",
        "                 cur_objs_num,\n",
        "                 out_path,\n",
        "                 middle_result_txt_file,\n",
        "                 post_processing = False,\n",
        "                 SSIM_total=np.array([0., 0.]),\n",
        "                 PSNR_total=np.array([0., 0.])):\n",
        "\n",
        "    num_samples = batch.shape[0]\n",
        "    sample = min_max_norm(sample)\n",
        "    batch = min_max_norm(batch)\n",
        "    import copy\n",
        "    sample_before = copy.deepcopy(sample)\n",
        "\n",
        "    if(post_processing):\n",
        "        print(\"post_processing\")\n",
        "        inverse_mask = 1. - mask\n",
        "        sample = sample[:,:,None,:,:]\n",
        "        f_masked_data = fftc(measurement) * mask + fftc(sample) * inverse_mask\n",
        "        masked_data = ifftc(f_masked_data).to(sample.dtype)\n",
        "        sample = masked_data[:,:,0,:,:]\n",
        "        sample = min_max_norm(sample)\n",
        "    measurement = min_max_norm(measurement).cpu().detach()\n",
        "    set_obj_SSIM, set_obj_PSNR = metrics_calculate(prediction=sample,\n",
        "                                                GT=batch,\n",
        "                                                cur_objs_num = cur_objs_num,\n",
        "                                                parent_dir=out_path,\n",
        "                                                raw_data=measurement,\n",
        "                                                middle_result_txt_file=middle_result_txt_file)\n",
        "    SSIM_total += set_obj_SSIM\n",
        "    PSNR_total += set_obj_PSNR\n",
        "    print('Current batch metrics: ', set_obj_SSIM / num_samples, set_obj_PSNR / num_samples, np.mean(set_obj_SSIM) / num_samples, np.mean(set_obj_PSNR) / num_samples)\n",
        "\n",
        "    total_considered_objs = cur_objs_num + num_samples\n",
        "    cur_SSIM_total = SSIM_total / total_considered_objs\n",
        "    cur_PSNR_total = PSNR_total / total_considered_objs\n",
        "    print('Current total: ', cur_SSIM_total, cur_PSNR_total, np.mean(cur_SSIM_total), np.mean(cur_PSNR_total))\n",
        "\n",
        "    result_line = f'Total number of considered objects {total_considered_objs} - SSIM: {cur_SSIM_total} PSNR:{cur_PSNR_total} SSIM mean: {np.mean(cur_SSIM_total)} PSNR common: {np.mean(cur_PSNR_total)}\\n'\n",
        "\n",
        "    with open(middle_result_txt_file, 'a+') as file:\n",
        "        file.write(result_line)\n",
        "\n",
        "    return SSIM_total, PSNR_total"
      ],
      "metadata": {
        "id": "bqJ2binvqWOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "cond_config = task_config['conditioning']\n",
        "hyper_params_to_search = list(task_config['conditioning']['params'].keys())\n",
        "hyper_params_list = [cond_config['params'][x] for x in hyper_params_to_search]\n",
        "hyper_param_combinations = list(itertools.product(*hyper_params_list))\n",
        "len(hyper_param_combinations)"
      ],
      "metadata": {
        "id": "Vw-1LR5BuPin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hyper_param_combinations"
      ],
      "metadata": {
        "id": "VB3dyHNF4Ugt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6BIgO3tO4XXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_new_config(original_config, hp_names, hp_values):\n",
        "    for name, value in zip(hp_names, hp_values):\n",
        "        original_config['params'][name] = value\n",
        "    return original_config"
      ],
      "metadata": {
        "id": "1ZiXoBQGv8Do"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def min_max_norm(data):\n",
        "    min_ = torch.amin(data, dim=(-2,-1), keepdim=True)\n",
        "    max_ = torch.amax(data, dim=(-2,-1), keepdim=True)\n",
        "    return (data - min_) / (max_ - min_)"
      ],
      "metadata": {
        "id": "YM_I2QqAyygi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_samples_to_consider = 500.\n",
        "\n",
        "#sample, batch, measurement, mask = None, None, None, None\n",
        "\n",
        "for cur_hp in hyper_param_combinations:\n",
        "    print(cur_hp)\n",
        "    cond_config = set_new_config(original_config=cond_config,\n",
        "                            hp_names=hyper_params_to_search,\n",
        "                            hp_values=cur_hp)\n",
        "\n",
        "\n",
        "    method_folder = f'''T{modalities}_{dataset_mode}_{dataset_name}_{hyper_params_to_search}'''.replace('\\n', '')\n",
        "\n",
        "    unique_add_results_folder = f'''{hyper_params_to_search}_{cur_hp}_'''.replace('\\n', '')\n",
        "\n",
        "    result_folder = f'{result_folder_parent_part}/{method_folder}/{unique_add_results_folder}'\n",
        "    os.makedirs(result_folder, exist_ok=True)\n",
        "\n",
        "    out_path = os.path.join(result_folder, measure_config['operator']['name'])\n",
        "    os.makedirs(out_path, exist_ok=True)\n",
        "    for img_dir in ['input', 'recon', 'progress', 'label']:\n",
        "        os.makedirs(os.path.join(out_path, img_dir), exist_ok=True)\n",
        "\n",
        "    cond_method = get_conditioning_method(cond_config['method'], operator, noiser, **cond_config['params'])\n",
        "    measurement_cond_fn = cond_method.conditioning\n",
        "\n",
        "    sampler = create_sampler(**diffusion_config)\n",
        "    sample_fn = partial(sampler.p_sample_loop, model=model, measurement_cond_fn=measurement_cond_fn)\n",
        "\n",
        "    SSIM_total = np.array([0.] * modalities_num)\n",
        "    PSNR_total = np.array([0.] * modalities_num)\n",
        "\n",
        "    #SSIM_total_post = np.array([])\n",
        "    #PSNR_total_post = np.array([])\n",
        "\n",
        "    middle_result_txt_file = os.path.join(result_folder, 'middle_results.txt')\n",
        "    middle_result_txt_file_postprocessing = os.path.join(result_folder, 'middle_results_post_processing.txt')\n",
        "    for i, all_batch in tqdm(enumerate(loader)):\n",
        "        if(i < total_samples_to_consider):\n",
        "            print('HI')\n",
        "            fname = str(i).zfill(5) + '.png'\n",
        "\n",
        "            all_batch = [x.to(device) for x in all_batch]\n",
        "            #batch - [9, 2, 1, 128, 128] - [batch_size; modalities; channels; spatial#1, spatial#2]\n",
        "            #measurа ement - [9, 2, 1, 128, 128] - [batch_size; modalities; channels; spatial#1, spatial#2]\n",
        "            #mask - [9, 1, 1, 128, 128] - [batch_size; modalities; channels; spatial#1, spatial#2]\n",
        "\n",
        "            batch, measurement, mask = all_batch\n",
        "\n",
        "            #x_start - [9, 2, 128, 128] - [batch_size; channels; spatial#1, spatial#2]\n",
        "            x_start = torch.randn(batch[:,:,0,].shape, device=device).requires_grad_()\n",
        "\n",
        "            meas_support = dict()\n",
        "            meas_support['mask'] = mask\n",
        "\n",
        "            sample = sample_fn(x_start=x_start, measurement=measurement,\n",
        "                               meas_support=meas_support,\n",
        "                               record=True, save_root=out_path,)\n",
        "\n",
        "            sample = sample.cpu().detach()\n",
        "            batch = batch.cpu().detach()\n",
        "            measurement = measurement.cpu().detach()\n",
        "            mask = mask.cpu().detach()\n",
        "\n",
        "            SSIM_total, PSNR_total = call_metrics(sample=sample,\n",
        "                         batch=batch,\n",
        "                         measurement=measurement,\n",
        "                         mask=mask,\n",
        "                         cur_objs_num = i * batch_size,\n",
        "                         out_path=out_path,\n",
        "                         middle_result_txt_file=middle_result_txt_file,\n",
        "                         post_processing = False,\n",
        "                         SSIM_total=SSIM_total,\n",
        "                         PSNR_total=PSNR_total)\n",
        "            \"\"\"\n",
        "            SSIM_total_post, PSNR_total_post = call_metrics(sample=sample,\n",
        "                         batch=batch,\n",
        "                         measurement=measurement,\n",
        "                         mask=mask,\n",
        "                         cur_objs_num = i * batch_size,\n",
        "                         out_path=out_path,\n",
        "                         middle_result_txt_file=middle_result_txt_file_postprocessing,\n",
        "                         post_processing = True,\n",
        "                         SSIM_total=SSIM_total_post,\n",
        "                         PSNR_total=PSNR_total_post)\n",
        "            \"\"\"\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    \"\"\"\n",
        "    SSIM_total /= (total_samples_to_consider * batch_size)\n",
        "    PSNR_total /= (total_samples_to_consider * batch_size)\n",
        "    print('SSIM_total', SSIM_total)\n",
        "    print('PSNR_total', PSNR_total)\n",
        "    result_line = f'Total~ {total_samples_to_consider * batch_size} objects POST - SSIM: {SSIM_total_post} PSNR:{PSNR_total_post} SSIM mean: {np.mean(SSIM_total)} PSNR common: {np.mean(PSNR_total)}\\n'\n",
        "\n",
        "    with open(os.path.join(result_folder, 'final_results.txt'), 'a+') as file:\n",
        "        file.write(result_line)\n",
        "\n",
        "\n",
        "    SSIM_total_post /= (total_samples_to_consider * batch_size)\n",
        "    PSNR_total_post /= (total_samples_to_consider * batch_size)\n",
        "    print('SSIM_total', SSIM_total_post)\n",
        "    print('PSNR_total', PSNR_total_post)\n",
        "    result_line = f'Total~ {total_samples_to_consider * batch_size} objects POST - SSIM: {SSIM_total_post} PSNR:{PSNR_total_post} SSIM mean: {np.mean(cur_SSIM_total)} PSNR common: {np.mean(cur_PSNR_total)}\\n'\n",
        "\n",
        "    with open(os.path.join(result_folder, 'final_results.txt'), 'a+') as file:\n",
        "        file.write(result_line)\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "MLUrWK-qCE-C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}